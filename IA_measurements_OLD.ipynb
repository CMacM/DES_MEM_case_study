{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "import des_functions\n",
    "import treecorr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from more_itertools import locate\n",
    "import time\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['cmr10']\n",
    "plt.rcParams['mathtext.fontset'] ='cm'\n",
    "data_dir = '/home/b7009348/projects/WGL_Project/DES-data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bin and scale params\n",
    "nbins=20\n",
    "npatches=20\n",
    "theta_min=2.5\n",
    "theta_max=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to required files\n",
    "data_dir = '/home/b7009348/projects/WGL_Project/DES-data/'\n",
    "lens_file = 'DES_Y1A1_Lenses_z=0.3-0.45.fits'\n",
    "source_Zs = 'y1a1-gold-mof-badregion_BPZ.fits'\n",
    "im3_file = 'y1_im3_shapes_matched.fits'\n",
    "mcal_file = 'y1_mcal_shapes_matched.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im3_tangential_shear(cat_l, cat_s, cat_r, cat_k, nbins):\n",
    "    \n",
    "    gammat = np.zeros([nbins])\n",
    "    theta = np.zeros_like(gammat)\n",
    "    \n",
    "    # do correlations with lenese, NKCorrelation is used to apply multiplicative correction\n",
    "    ng = treecorr.NGCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    ng.process(cat_l, cat_s)\n",
    "    nk = treecorr.NKCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    nk.process(cat_l, cat_k)\n",
    "    \n",
    "    # do correlations with randoms\n",
    "    rg = treecorr.NGCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    rg.process(cat_r, cat_s)\n",
    "    rk = treecorr.NKCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    rk.process(cat_r, cat_k)\n",
    "    \n",
    "    # correlation functions and corrections for lenses and randoms\n",
    "    xi_l = ng.xi\n",
    "    sens_l = nk.xi\n",
    "    xi_r = rg.xi\n",
    "    sens_r = rk.xi\n",
    "    \n",
    "    # store data in preallocated arrays\n",
    "    gammat[:] = xi_l/sens_l - xi_r/sens_r\n",
    "    theta[:] = np.exp(ng.meanlogr)\n",
    "    \n",
    "    del ng, rg, nk, rk, xi_l, sens_l, xi_r, sens_r\n",
    "    \n",
    "    return gammat, theta\n",
    "\n",
    "def calculate_boost(cat_l, cat_s, cat_r, nbins):\n",
    "    \n",
    "    boost = np.zeros([nbins])\n",
    "    \n",
    "    # do count correlations to find boost\n",
    "    ls = treecorr.NNCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    ls.process(cat_l, cat_s)\n",
    "\n",
    "    rs = treecorr.NNCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    rs.process(cat_r, cat_s)\n",
    "    \n",
    "    nrand = cat_r.nobj\n",
    "    nlens = cat_l.nobj\n",
    "    \n",
    "    boost[:] = nrand/nlens * ls.weight/rs.weight\n",
    "    \n",
    "    del ls, rs, nrand, nlens\n",
    "    \n",
    "    return boost\n",
    "\n",
    "def mcal_tangential_shear(cat_l, cat_s, cat_r, nbins, R):\n",
    "    \n",
    "    gammat = np.zeros([nbins])\n",
    "    theta = np.zeros_like(gammat)\n",
    "    \n",
    "    # do correlations with lenses\n",
    "    ng = treecorr.NGCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    ng.process(cat_l, cat_s)\n",
    "    \n",
    "    # do correlations with randoms\n",
    "    rg = treecorr.NGCorrelation(nbins=nbins, min_sep=theta_min, max_sep=theta_max, sep_units='arcmin')\n",
    "    rg.process(cat_r, cat_s)\n",
    "    \n",
    "    # correlation functions and corrections for lenses and randoms\n",
    "    xi_l = ng.xi\n",
    "    xi_r = rg.xi\n",
    "    \n",
    "    # store data in preallocated arrays\n",
    "    gammat[:] = 1.0/R * (xi_l - xi_r)\n",
    "    theta[:] = np.exp(ng.meanlogr)\n",
    "    \n",
    "    del ng, rg, xi_l, xi_r\n",
    "    \n",
    "    return gammat, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lens catalogue created...\n"
     ]
    }
   ],
   "source": [
    "# read in lens data and create treecorr catalogue object to store\n",
    "with fits.open(data_dir+lens_file) as hdu:\n",
    "    data = hdu[1].data\n",
    "    ra_l = data['RA']\n",
    "    dec_l = data['DEC']\n",
    "    w_l = data['weight']\n",
    "    \n",
    "# pass in npatch arguement to create catalogue using patches    \n",
    "cat_l = treecorr.Catalog(ra=ra_l, dec=dec_l, ra_units='deg', dec_units='deg', w=w_l, npatch=npatches)\n",
    "\n",
    "del data, ra_l, dec_l, w_l\n",
    "\n",
    "print('lens catalogue created...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Jackknife estimate...\n",
      "randoms catalogue created...\n",
      "IM3SHAPE catalogue created...\n",
      "METACALIBRATION catalogue created...\n",
      "ALL CATALOGUES READY\n",
      "Patch 0 located...\n",
      "Number of sources in patch: 17191095.000000\n",
      "Total number of sources: 17865244.000000\n",
      "im3 shear calculation complete...\n",
      "[1.41475260e-03 1.20410073e-03 8.87710136e-04 7.21005759e-04\n",
      " 5.26490897e-04 4.15709516e-04 2.96922598e-04 2.42619110e-04\n",
      " 2.58458338e-04 1.99381172e-04 1.45701232e-04 1.18410922e-04\n",
      " 1.31141915e-04 9.25882229e-05 7.83986704e-05 7.92036717e-05\n",
      " 6.87457731e-05 5.36430455e-05 4.97922091e-05 4.28777567e-05]\n",
      "mcal shear calculation complete...\n",
      "[1.28724652e-03 1.03159598e-03 7.88934989e-04 6.97915789e-04\n",
      " 4.96209165e-04 3.60291535e-04 2.97436656e-04 2.18397836e-04\n",
      " 2.15132670e-04 1.70941686e-04 1.27570329e-04 1.20788291e-04\n",
      " 1.20432484e-04 8.19810229e-05 7.25396104e-05 6.96841035e-05\n",
      " 5.30274529e-05 4.42032996e-05 3.87967619e-05 4.42217079e-05]\n",
      "boost calculation complete...\n",
      "[1.04783087 1.03403451 1.02808652 1.02312483 1.02009079 1.01760527\n",
      " 1.01617113 1.01208786 1.01123895 1.0084821  1.00866123 1.00575817\n",
      " 1.00578473 1.00337049 1.00380354 1.00136869 0.99987694 1.00169994\n",
      " 0.99741855 1.00161707]\n",
      "F calculation complete...\n",
      "0.07319770712882744\n",
      "Signal estimated, patch runtime = 694.319672. Beginning next patch...\n",
      "randoms catalogue created...\n"
     ]
    }
   ],
   "source": [
    "IA_signal = np.zeros([npatches, nbins])\n",
    "theta = np.zeros_like(IA_signal)\n",
    "#loop to exclude 1 patch at a time\n",
    "print('Beginning Jackknife estimate...')\n",
    "for i in range(npatches):\n",
    "    \n",
    "    im3_gammat = np.zeros([nbins])\n",
    "    im3_theta = np.zeros_like(im3_gammat)\n",
    "    mcal_gammat = np.zeros_like(im3_gammat)\n",
    "    mcal_theta = np.zeros_like(im3_gammat)\n",
    "    boost = np.zeros_like(im3_gammat)\n",
    "    F = np.zeros_like(im3_gammat)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # read in randoms data and create treecorr catalogue\n",
    "    with fits.open(data_dir+'DES_Y1A1_3x2pt_redMaGiC_RANDOMS.fits') as hdu:\n",
    "        data = hdu[1].data\n",
    "        indexes = list(locate(data['z'], lambda x: 0.3 < x < 0.45)) # cut randoms to same redshift as lenses \n",
    "        ra_r = data['RA'][indexes]\n",
    "        dec_r = data['dec'][indexes]\n",
    "        lens_z = data['z'][indexes]\n",
    "    \n",
    "    # define patches based on patches from lens catalogue so all catalogues use the same patches    \n",
    "    cat_r = treecorr.Catalog(ra=ra_r, dec=dec_r, ra_units='deg', dec_units='deg', r=lens_z, patch_centers=cat_l.patch_centers)\n",
    "\n",
    "    del data, ra_r, dec_r, indexes, lens_z\n",
    "    \n",
    "    print('randoms catalogue created...')\n",
    "\n",
    "    with fits.open(data_dir+im3_file) as hdu:\n",
    "        data = hdu[1].data\n",
    "        im3_ID = data['coadd_objects_id']\n",
    "        ra_s = data['ra']\n",
    "        dec_s = data['dec']\n",
    "        e1 = data['e1'] - data['c1']\n",
    "        e2 = data['e2'] - data['c2']\n",
    "        sens = data['m'] + 1.0\n",
    "        w = data['weight']\n",
    "    del data\n",
    "    \n",
    "    # load in z_mc for all sources\n",
    "    with fits.open(data_dir+'y1a1-gold-mof-badregion_BPZ.fits') as hdu:\n",
    "        data = hdu[1].data\n",
    "        im3_zmc = data['Z_MC']\n",
    "        zmc_ID = data['COADD_OBJECTS_ID']\n",
    "    del data\n",
    "\n",
    "    # match z_mc values to source IDs\n",
    "    matches, zmc_indices, shape_indices = np.intersect1d(zmc_ID, im3_ID, return_indices=True)\n",
    "\n",
    "    # slice z_mc values to only to those in matched catalogue\n",
    "    im3_zmc = im3_zmc[zmc_indices]\n",
    "\n",
    "    # delete uneccessary arrays\n",
    "    del matches, zmc_indices, shape_indices, zmc_ID, im3_ID\n",
    "    \n",
    "    cat_im3 = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', r=im3_zmc, g1=e1, g2=e2, w=w, patch_centers=cat_l.patch_centers)\n",
    "    cat_k = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', k=sens, w=w, patch_centers=cat_l.patch_centers)\n",
    "\n",
    "    del ra_s, dec_s, w, e1, e2, sens, im3_zmc\n",
    "\n",
    "    print('IM3SHAPE catalogue created...')\n",
    "\n",
    "    with fits.open(data_dir+mcal_file) as hdu:\n",
    "        data = hdu[1].data\n",
    "        ra_s = data['ra']\n",
    "        dec_s = data['dec']\n",
    "        e1 = data['e1']\n",
    "        e2 = data['e2']\n",
    "        R11 = data['R11'] # e1-e1\n",
    "    \n",
    "    R = np.mean(R11)\n",
    "    cat_mcal = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', g1=e1, g2=e2, patch_centers=cat_l.patch_centers)\n",
    "\n",
    "    del data, ra_s, dec_s, e1, e2, R11\n",
    "\n",
    "    print('METACALIBRATION catalogue created...')\n",
    "    print('ALL CATALOGUES READY')\n",
    "    \n",
    "    #locate patch in catlogues\n",
    "    l_indexes = list(locate(cat_l.patch, lambda x: x != i))\n",
    "    r_indexes = list(locate(cat_r.patch, lambda x: x != i))\n",
    "    im3_indexes = list(locate(cat_im3.patch, lambda x: x != i))\n",
    "    k_indexes = list(locate(cat_k.patch, lambda x: x != i))\n",
    "    mcal_indexes = list(locate(cat_mcal.patch, lambda x: x != i))\n",
    "    \n",
    "    print('Patch %g located...' %i)\n",
    "    \n",
    "    #create new catalogues with this patch missing\n",
    "    jk_l = treecorr.Catalog(ra=cat_l.ra[l_indexes], dec=cat_l.dec[l_indexes], ra_units='rad', dec_units='rad', w=cat_l.w[l_indexes])\n",
    "    \n",
    "    jk_r = treecorr.Catalog(ra=cat_r.ra[r_indexes], dec=cat_r.dec[r_indexes], ra_units='rad', dec_units='rad', w=cat_r.w[r_indexes])\n",
    "    \n",
    "    jk_im3 = treecorr.Catalog(ra=cat_im3.ra[im3_indexes], dec=cat_im3.dec[im3_indexes], ra_units='rad', dec_units='rad', g1=cat_im3.g1[im3_indexes], \n",
    "                                g2=cat_im3.g2[im3_indexes], w=cat_im3.w[im3_indexes])\n",
    "    \n",
    "    jk_k = treecorr.Catalog(ra=cat_k.ra[k_indexes], dec=cat_k.dec[k_indexes], ra_units='rad', dec_units='rad', k=cat_k.k[k_indexes], \n",
    "                                w=cat_k.w[k_indexes])\n",
    "    \n",
    "    jk_mcal = treecorr.Catalog(ra=cat_mcal.ra[mcal_indexes], dec=cat_mcal.dec[mcal_indexes], ra_units='rad', dec_units='rad', g1=cat_mcal.g1[mcal_indexes], \n",
    "                                g2=cat_mcal.g2[mcal_indexes])\n",
    "    \n",
    "    lens_z = cat_r.r[r_indexes]\n",
    "    source_z = cat_im3.r[im3_indexes]\n",
    "    source_weights = cat_im3.w[im3_indexes]\n",
    "    \n",
    "    print('Number of sources in patch: %f' %jk_im3.nobj)\n",
    "    print('Total number of sources: %f' %cat_im3.nobj)\n",
    "    \n",
    "    del l_indexes, r_indexes, im3_indexes, k_indexes, mcal_indexes, cat_im3, cat_mcal, cat_r, cat_k\n",
    "    \n",
    "    im3_gammat, im3_theta = im3_tangential_shear(cat_l=jk_l, cat_s=jk_im3, cat_r=jk_r, cat_k=jk_k, nbins=nbins)\n",
    "    \n",
    "    print('im3 shear calculation complete...')\n",
    "    print(im3_gammat)\n",
    "    \n",
    "    mcal_gammat, mcal_theta = mcal_tangential_shear(cat_l=jk_l, cat_s=jk_mcal, cat_r=jk_r, nbins=nbins, R=R)\n",
    "    \n",
    "    print('mcal shear calculation complete...')\n",
    "    print(mcal_gammat)\n",
    "    \n",
    "    boost = calculate_boost(cat_l=jk_l, cat_s=jk_im3, cat_r=jk_r, nbins=nbins)\n",
    "    \n",
    "    print('boost calculation complete...')\n",
    "    print(boost)\n",
    "    \n",
    "    F = des_functions.calculate_F(nbins=810, source_z=source_z, lens_z=lens_z, source_weights=source_weights)\n",
    "    \n",
    "    print('F calculation complete...')\n",
    "    print(F)\n",
    "    \n",
    "    IA_signal[i,:] = (im3_gammat - mcal_gammat) / (boost - 1.0 + F)\n",
    "    \n",
    "    end = time.time()\n",
    "    diff = end-start\n",
    "    \n",
    "    print ('Signal estimated, patch runtime = %f. Beginning next patch...' %diff)\n",
    "    \n",
    "    del jk_l, jk_r, jk_im3, jk_mcal, jk_k, lens_z, source_z, source_weights, im3_gammat, im3_theta, mcal_gammat, mcal_theta, boost, F\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1.29867928e-03 1.04790374e-03 8.43396462e-04 6.23296316e-04\n",
    " 4.98211099e-04 4.12308408e-04 2.64241219e-04 2.35359671e-04\n",
    " 1.99651778e-04 1.71579648e-04 1.39389203e-04 1.10589460e-04\n",
    " 1.23317968e-04 8.04852195e-05 7.53461476e-05 7.24331958e-05\n",
    " 5.46931060e-05 4.60124824e-05 4.09924232e-05 4.49363099e-05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im3_gammat = np.zeros([nbins])\n",
    "im3_theta = np.zeros_like(im3_gammat)\n",
    "mcal_gammat = np.zeros_like(im3_gammat)\n",
    "mcal_theta = np.zeros_like(im3_gammat)\n",
    "boost = np.zeros_like(im3_gammat)\n",
    "F = np.zeros_like(im3_gammat)\n",
    "\n",
    "IA_final = np.zeros([nbins])\n",
    "theta_final = np.zeros([nbins])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# read in lens data and create treecorr catalogue object to store\n",
    "with fits.open(data_dir+lens_file) as hdu:\n",
    "    data = hdu[1].data\n",
    "    ra_l = data['RA']\n",
    "    dec_l = data['DEC']\n",
    "    w_l = data['weight']\n",
    "    \n",
    "# pass in npatch arguement to create catalogue using patches    \n",
    "cat_l = treecorr.Catalog(ra=ra_l, dec=dec_l, ra_units='deg', dec_units='deg', w=w_l)\n",
    "\n",
    "del data, ra_l, dec_l, w_l\n",
    "\n",
    "print('lens catalogue created...')\n",
    "\n",
    "# read in randoms data and create treecorr catalogue\n",
    "with fits.open(data_dir+'DES_Y1A1_3x2pt_redMaGiC_RANDOMS.fits') as hdu:\n",
    "    data = hdu[1].data\n",
    "    indexes = list(locate(data['z'], lambda x: 0.3 < x < 0.45)) # cut randoms to same redshift as lenses \n",
    "    ra_r = data['RA'][indexes]\n",
    "    dec_r = data['dec'][indexes]\n",
    "    lens_z = data['z'][indexes]\n",
    "\n",
    "# define patches based on patches from lens catalogue so all catalogues use the same patches    \n",
    "cat_r = treecorr.Catalog(ra=ra_r, dec=dec_r, ra_units='deg', dec_units='deg')\n",
    "\n",
    "del data, ra_r, dec_r, indexes\n",
    "\n",
    "print('randoms catalogue created...')\n",
    "\n",
    "with fits.open(data_dir+im3_file) as hdu:\n",
    "    data = hdu[1].data\n",
    "    im3_ID = data['coadd_objects_id']\n",
    "    ra_s = data['ra']\n",
    "    dec_s = data['dec']\n",
    "    e1 = data['e1'] - data['c1']\n",
    "    e2 = data['e2'] - data['c2']\n",
    "    sens = data['m'] + 1.0\n",
    "    w = data['weight']\n",
    "del data\n",
    "\n",
    "# load in z_mc for all sources\n",
    "with fits.open(data_dir+'y1a1-gold-mof-badregion_BPZ.fits') as hdu:\n",
    "    data = hdu[1].data\n",
    "    im3_zmc = data['Z_MC']\n",
    "    zmc_ID = data['COADD_OBJECTS_ID']\n",
    "del data\n",
    "\n",
    "# match z_mc values to source IDs\n",
    "matches, zmc_indices, shape_indices = np.intersect1d(zmc_ID, im3_ID, return_indices=True)\n",
    "\n",
    "# slice z_mc values to only to those in matched catalogue\n",
    "im3_zmc = im3_zmc[zmc_indices]\n",
    "\n",
    "# delete uneccessary arrays\n",
    "del matches, zmc_indices, shape_indices, zmc_ID, im3_ID\n",
    "\n",
    "cat_im3 = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', g1=e1, g2=e2, w=w)\n",
    "cat_k = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', k=sens, w=w)\n",
    "\n",
    "del ra_s, dec_s, w, e1, e2, sens\n",
    "\n",
    "print('IM3SHAPE catalogue created...')\n",
    "\n",
    "with fits.open(data_dir+mcal_file) as hdu:\n",
    "    data = hdu[1].data\n",
    "    ra_s = data['ra']\n",
    "    dec_s = data['dec']\n",
    "    e1 = data['e1']\n",
    "    e2 = data['e2']\n",
    "    R11 = data['R11'] # e1-e1\n",
    "\n",
    "R = np.mean(R11)\n",
    "cat_mcal = treecorr.Catalog(ra=ra_s, dec=dec_s, ra_units='deg', dec_units='deg', g1=e1, g2=e2)\n",
    "\n",
    "del data, ra_s, dec_s, e1, e2, R11\n",
    "\n",
    "print('METACALIBRATION catalogue created...')\n",
    "print('ALL CATALOGUES READY')\n",
    "\n",
    "source_weights = cat_im3.w\n",
    "\n",
    "im3_gammat, im3_theta = im3_tangential_shear(cat_l=cat_l, cat_s=cat_im3, cat_r=cat_r, cat_k=cat_k, nbins=nbins)\n",
    "\n",
    "print('im3 shear calculation complete...')\n",
    "\n",
    "mcal_gammat, mcal_theta = mcal_tangential_shear(cat_l=cat_l, cat_s=cat_mcal, cat_r=cat_r, nbins=nbins, R=R)\n",
    "\n",
    "del cat_mcal\n",
    "\n",
    "print('mcal shear calculation complete...')\n",
    "\n",
    "boost = calculate_boost(cat_l=cat_l, cat_s=cat_im3, cat_r=cat_r, nbins=nbins)\n",
    "\n",
    "del cat_im3, cat_l, cat_r\n",
    "\n",
    "print('boost calculation complete...')\n",
    "\n",
    "F = des_functions.calculate_F(nbins=810, source_z=im3_zmc, lens_z=lens_z, source_weights=source_weights)\n",
    "\n",
    "del lens_z, im3_zmc, source_weights,\n",
    "\n",
    "print('F calculation complete...')\n",
    "\n",
    "IA_final[:] = (im3_gammat - mcal_gammat) / (boost - 1.0 + F)\n",
    "theta_final[:] = mcal_theta\n",
    "\n",
    "del im3_gammat, im3_theta, mcal_gammat, mcal_theta, boost, F\n",
    "\n",
    "end = time.time()\n",
    "diff = end-start\n",
    "\n",
    "print ('Signal estimated, patch runtime = %f. Beginning next patch...' %diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IA_var = np.zeros([nbins])\n",
    "for i in range(nbins):\n",
    "    # each row of GammaT_patches corresponds to an x_i estimate\n",
    "    IA_var[i] = (npatches-1)/npatches * np.sum((IA_signal[:,i] - IA_final[i])**2) # sum over x_i - x\n",
    "    \n",
    "IA_sig = np.sqrt(IA_var)\n",
    "\n",
    "print(IA_final, IA_sig)\n",
    "\n",
    "plt.figure(figsize=[6,5])\n",
    "plt.errorbar(theta_final, IA_final, yerr=IA_sig, lw=0, marker='o', color='orange', markersize=5, elinewidth=1, capsize=3)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim([1e-6, 1e-2])\n",
    "plt.xlim([2.5,250])\n",
    "plt.xlabel(r'$\\theta$ (arcmin)')\n",
    "plt.ylabel(r'$\\bar{\\gamma}_{IA}(\\theta)$')\n",
    "plt.title(r'$0.30<z_{l}<0.45$')\n",
    "plt.savefig('IA_prelim_measurement.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
